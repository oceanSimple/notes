---
cssclass:
  - img-grid
---
# ♾️模型评估与选择
## 💫评估方法
- 交叉验证法
- 留出法
- 自助法

## 💫性能度量
### 回归常用：均方误差
![[Pasted image 20240426174312.png|314]]


### 查准率，查全率，F1
![[Pasted image 20240426174417.png|398]]
![[Pasted image 20240426174435.png|409]]

```ad-info
如何理解查准率和查全率的意义
```
举例：医学范围，认为有肺结核的为阳性P，没有肺结核的为阴性N
- TP：预测阳性，真实阳性
- FP：预测阳性，真实阴性（误判，将没病的认为有病）
- FN：预测阴性，真实阳性（漏判，将有病的漏掉了）
- TN：预测阴性，真实阴性（没啥用）
在医学领域，应该尽量找出患者，即错杀而不漏杀，因此看重查全率。
在搜索引擎领域，用户更关注你给的内容是不是我感兴趣的，因此看重查准率


- 查全率和查准率互相矛盾，很难两全其美
![[Pasted image 20240426174524.png]]
平衡点即P=R的位置

```ad-note
F1度量
```
![[Pasted image 20240426174610.png]]
一般形式
![[Pasted image 20240426174628.png]]
- β=1，标准的F1
- β>1，倾向于查全率
- β<1，倾向于查准率

### 宏/微查准率、查全率

> 当我们多次进行训练/测试时，得到多个混淆矩阵


```ad-note
宏
```
![[Pasted image 20240426174900.png|378]]
```ad-note
微
```
![[Pasted image 20240426174929.png|329]]

### ROC，AUC
没看懂0.0

### 代价敏感错误率和代价曲线
```ad-note
非均等代价
```
考虑一个门禁系统，允许通过为1，不允许通过为0
- 错误1：禁止工作人员进入
- 错误2：允许危险人员进入
很显然，错误1只会带来体验问题，而错误2的问题更加严重

代价敏感错误率，即为不同的错误赋予不同的权重
![[Pasted image 20240426182925.png|525]]
ps：D+是错误1，D-是错误2的集合

```ad-note
代价曲线：暂略
```

## 💫比较校验
> 暂略

- 假设校验
- 交叉校验t检验
- McNemar检验
- Friedman检验与Nemenyi后续检验

## 💫偏差与方差
暂略，推荐链接：https://zhuanlan.zhihu.com/p/38853908

# ♾️线性模型

# ♾️决策树
## 💫划分选择
> 信息熵

![[Pasted image 20240509184013.png]]
Ent(D)越小，纯度越高

 > 信息增益
 
 ![[Pasted image 20240509185055.png]]
 信息增益越大，使用属性a的划分纯度越大

> 增益率

![[Pasted image 20240509185819.png]]
增益率准则对可取值数目较少的属性有所偏好
C4.5算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式]:先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的.

> 基尼指数

![[Pasted image 20240509190107.png]]
直观来说，G in i(P )反映了从数据集D 中随机抽取两个样本，其类别标记不一致的概率.因此,Gini(D)越小，则数据集D 的纯度越高.

## 💫剪枝处理
分为预剪枝和后剪枝
- 预剪枝更方便，更快，分支更少，因此容易欠拟合
- 后剪枝由下到上，更慢，但相比预剪枝不易欠拟合

## 💫连续值处理
考虑n-1个候选点
![[Pasted image 20240509202618.png]]
分别计算每个候选划分点的信息增益，选取最大的为代表
![[Pasted image 20240509202657.png]]
 ！注意
 - 与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性.

## 💫缺失值处理
取出不含缺失值的子类计算信息增益，ρ=非缺失值/总数目
![[Pasted image 20240509204018.png]]

## 💫多变量决策树
多个变量组合成一个条件结点

# ♾️神经网络
## 💫神经元模型
![[Pasted image 20240514132035.png]]

> 激活函数

![[Pasted image 20240514132121.png]]


## 💫感知机和多层网络
> 感知机

![[Pasted image 20240514132453.png]]
感 知 机 (Perceptron)由 两 层 神 经 元 组 成 ，如 图 5 .3 所示，输入层接收外界 输 入 信 号 后 传 递 给 输 出 层 ，输 出 层 是 M -P 神 经 元 ，亦 称 “阈值逻辑单元 ”(threshold logic unit).

感知机能容易地实现逻辑与、或、非运算.
- 与：x<sub>1</sub>=1 & x<sub>2</sub>=1时，y=1
$$y=f(x_1+x_2-2)$$
- 或：x<sub>1</sub>=1 | x<sub>2</sub>=1时，y=1
$$y=f(x_1+x_2-0.5)$$
- 非：x<sub>1</sub>=1，y=0 ； x<sub>1</sub>=0，y=1
$$y=f(-0.6x_1+0.5)$$
> 多层前馈神经网络结构


![[Pasted image 20240514133233.png]]
输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元.

## 💫误差逆传播算法-BP算法


# ♾️支持向量机-SVM

- SVM就是一种二类分类模型，他的基本模型是的定义在特征空间上的**间隔最大**的线性分类器，SVM的学习策略就是间隔最大化。
- 两类点被一条直线完全分开叫做线性可分。